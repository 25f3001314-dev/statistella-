{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 14420894,
          "sourceType": "datasetVersion",
          "datasetId": 9210627
        },
        {
          "sourceId": 14436476,
          "sourceType": "datasetVersion",
          "datasetId": 9221292
        },
        {
          "sourceId": 14436504,
          "sourceType": "datasetVersion",
          "datasetId": 9221313
        },
        {
          "sourceId": 14443970,
          "sourceType": "datasetVersion",
          "datasetId": 9226301
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "SHIVOM Statistella-8-0-round-2  eec0db",
      "provenance": [],
      "gpuType": "V5E1"
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "_uuid": "3c3e139b-9401-4ac9-9288-b109f5d44e37",
        "_cell_guid": "834c07e0-fdd7-4e62-a4d7-f69878fc2f05",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-09T10:54:05.319169Z",
          "iopub.execute_input": "2026-01-09T10:54:05.319403Z",
          "iopub.status.idle": "2026-01-09T10:54:09.358082Z",
          "shell.execute_reply.started": "2026-01-09T10:54:05.319367Z",
          "shell.execute_reply": "2026-01-09T10:54:09.357356Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKWaSOLNZ7Zg",
        "outputId": "1f2b002a-526f-4be6-bdd2-8e8019840098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Data Cleaning (Loading & Initial Checks)\n",
        "\n",
        "The first step focuses on loading the dataset and performing basic sanity checks.\n",
        "This ensures that the data is correctly read and ready for further analysis"
      ],
      "metadata": {
        "id": "VoyTbW6KZ7Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a) Data Loading\n",
        "\n",
        "**What we did:**\n",
        "- Loaded the training and test datasets using `pandas.read_csv`.\n",
        "- Separated training and test data for proper model development and evaluation.\n",
        "\n",
        "**Why we did this:**\n",
        "- Proper data loading is essential to avoid file path or schema errors.\n",
        "- Keeping train and test data separate prevents data leakage.\n"
      ],
      "metadata": {
        "id": "rky5u09fZ7Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test  = pd.read_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "_uuid": "cbc52bae-7a03-482d-b6aa-49b966168753",
        "_cell_guid": "ff32ca83-5e27-4425-9c44-45f5b230fd7c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-09T10:56:44.416114Z",
          "iopub.execute_input": "2026-01-09T10:56:44.416981Z",
          "iopub.status.idle": "2026-01-09T10:56:44.426157Z",
          "shell.execute_reply.started": "2026-01-09T10:56:44.416948Z",
          "shell.execute_reply": "2026-01-09T10:56:44.425234Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "cVKcAXe6Z7Zn",
        "outputId": "b3a30338-6bf1-42b7-9412-53306a27a872"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3271563943.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Data Exploration (EDA – Exploratory Data Analysis)"
      ],
      "metadata": {
        "_uuid": "c50c589b-a063-4493-8faa-c7e441dae0b6",
        "_cell_guid": "6f01f9f6-a6e4-43cb-80e7-381cd6769143",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "lFwUZhb3Z7Zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Shape (Size Understanding)"
      ],
      "metadata": {
        "_uuid": "d03ccf1d-3423-4e31-a882-0a61d747c792",
        "_cell_guid": "fe058e5f-d3a1-4d80-ba71-95cd90e77452",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MnD__RYxZ7Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "_uuid": "9add1c0e-3fe0-4df4-8128-19a635d0d516",
        "_cell_guid": "5a3fd041-7d7d-4193-9641-f70699706fa2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:23:48.956656Z",
          "iopub.execute_input": "2026-01-08T16:23:48.957008Z",
          "iopub.status.idle": "2026-01-08T16:23:48.962265Z",
          "shell.execute_reply.started": "2026-01-08T16:23:48.95698Z",
          "shell.execute_reply": "2026-01-08T16:23:48.961199Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "oeeXxBl-Z7Zt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schema & Data Types Inspection"
      ],
      "metadata": {
        "_uuid": "f81a8250-7b20-4c2e-865f-e01385c81b11",
        "_cell_guid": "8f26b1d0-4f6f-466b-a233-9643fd37f619",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "UgATCl6xZ7Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "_uuid": "265d64f4-812f-4956-8f6d-6371217884fa",
        "_cell_guid": "d31bbf06-8e6d-49a9-a94f-4aa75b15124d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:03.200449Z",
          "iopub.execute_input": "2026-01-08T15:59:03.200826Z",
          "iopub.status.idle": "2026-01-08T15:59:03.239203Z",
          "shell.execute_reply.started": "2026-01-08T15:59:03.200797Z",
          "shell.execute_reply": "2026-01-08T15:59:03.238168Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pNtOS7MsZ7Zv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample Records Inspection"
      ],
      "metadata": {
        "_uuid": "9fe9cfc6-6f3d-45fd-89c5-adf4578954f0",
        "_cell_guid": "1812fe88-0e9d-48ce-9c60-13aa7311f008",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1UED4BN2Z7Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "_uuid": "c8746eac-d425-49b5-a293-907953416dd9",
        "_cell_guid": "9163a5d7-8d1a-4cd9-aafe-c49a838b5357",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:07.170341Z",
          "iopub.execute_input": "2026-01-08T15:59:07.170738Z",
          "iopub.status.idle": "2026-01-08T15:59:07.205212Z",
          "shell.execute_reply.started": "2026-01-08T15:59:07.170708Z",
          "shell.execute_reply": "2026-01-08T15:59:07.204347Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "eKtYbUWkZ7Zw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Value Assessment (High-level)"
      ],
      "metadata": {
        "_uuid": "458f71e2-7f20-4fe1-9ee5-853b0a43148b",
        "_cell_guid": "f9f2f765-bb63-4d3a-ab34-6a7a058dd6e3",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ZrKGlbuSZ7Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isna().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "_uuid": "2acabcc3-d4f9-4c69-a7a3-8776a4ce96ee",
        "_cell_guid": "8eec2472-ef81-4ce8-ac17-fb2465477e06",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:11.025701Z",
          "iopub.execute_input": "2026-01-08T15:59:11.026058Z",
          "iopub.status.idle": "2026-01-08T15:59:11.049105Z",
          "shell.execute_reply.started": "2026-01-08T15:59:11.02603Z",
          "shell.execute_reply": "2026-01-08T15:59:11.047867Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "N3wjw2zYZ7Zx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Variable Sanity Check"
      ],
      "metadata": {
        "_uuid": "97e3b3d3-2048-478e-ac62-0bfa677f9b0f",
        "_cell_guid": "8963281c-c26a-4199-9ef0-2141e33e2f93",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "raYmJTNTZ7Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"Importance Score\"].describe()"
      ],
      "metadata": {
        "_uuid": "79dc45e1-7f36-4ab1-8e05-5f1036382033",
        "_cell_guid": "0e6a9d4a-88ad-47e0-8653-ce5933406c42",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:15.960744Z",
          "iopub.execute_input": "2026-01-08T15:59:15.96107Z",
          "iopub.status.idle": "2026-01-08T15:59:15.978193Z",
          "shell.execute_reply.started": "2026-01-08T15:59:15.961042Z",
          "shell.execute_reply": "2026-01-08T15:59:15.97725Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "A3GqEJgMZ7Zx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA summary\n",
        "*Exploratory Data Analysis was conducted to understand dataset size, structure, data types, and sample records. The analysis revealed multiple text-based features with missing values and a continuous target variable, indicating a regression problem suitable for NLP-based feature engineering**"
      ],
      "metadata": {
        "_uuid": "9d8c7954-a94a-4ed6-9fe6-f4660f285417",
        "_cell_guid": "217d1fcd-344a-485d-9407-d662597a7315",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "XzorqdSGZ7Zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Data Cleaning & Pre-Processing\n",
        "\n",
        "This step focuses on preparing the raw data for modeling by handling missing values\n",
        "and identifying categorical and numerical features.\n"
      ],
      "metadata": {
        "id": "B5lDeHCAZ7Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Identify Categorical Columns\n",
        "\n",
        "**What we did:**\n",
        "- Identified all categorical columns using data type `object`.\n",
        "- Stored their names for consistent preprocessing.\n",
        "\n",
        "**Why we did this:**\n",
        "- Categorical features require special handling before model training.\n",
        "- Identifying them early ensures uniform preprocessing for both train and test sets.\n"
      ],
      "metadata": {
        "id": "pQdwZAkOZ7Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "cat_cols"
      ],
      "metadata": {
        "_uuid": "00f892bc-09eb-4877-9921-6a7a6abb707d",
        "_cell_guid": "2d0420c3-4623-4dc8-902d-2828137fe337",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:21.010647Z",
          "iopub.execute_input": "2026-01-08T15:59:21.010987Z",
          "iopub.status.idle": "2026-01-08T15:59:21.022253Z",
          "shell.execute_reply.started": "2026-01-08T15:59:21.010961Z",
          "shell.execute_reply": "2026-01-08T15:59:21.021105Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9QQnMfqXZ7Zy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Handle Missing Values in Categorical Columns\n",
        "\n",
        "**What we did:**\n",
        "- Replaced missing values in all categorical columns with a placeholder value (`\"missing\"`).\n",
        "- Applied the same transformation to both training and test datasets.\n",
        "\n",
        "**Why we did this:**\n",
        "- Machine learning models cannot handle null values directly.\n",
        "- Using a consistent placeholder prevents information loss and data leakage.\n"
      ],
      "metadata": {
        "id": "xQsGSwJDZ7Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_cols:\n",
        "    train[col] = train[col].fillna(\"missing\")\n",
        "    test[col]  = test[col].fillna(\"missing\")"
      ],
      "metadata": {
        "_uuid": "fa566728-03e6-454f-a3ba-0fc17cfd1bad",
        "_cell_guid": "47d92e21-f475-4bdb-9153-afd71162bb34",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:24.615016Z",
          "iopub.execute_input": "2026-01-08T15:59:24.615461Z",
          "iopub.status.idle": "2026-01-08T15:59:24.660297Z",
          "shell.execute_reply.started": "2026-01-08T15:59:24.615432Z",
          "shell.execute_reply": "2026-01-08T15:59:24.659069Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "v_jFIKo3Z7Zz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"Importance Score\""
      ],
      "metadata": {
        "_uuid": "43eccc13-bdc5-47c2-a945-54afbf138da1",
        "_cell_guid": "e84522da-38d4-4d19-a044-4f66d3fcc9d4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:29.320396Z",
          "iopub.execute_input": "2026-01-08T15:59:29.320791Z",
          "iopub.status.idle": "2026-01-08T15:59:29.325485Z",
          "shell.execute_reply.started": "2026-01-08T15:59:29.320752Z",
          "shell.execute_reply": "2026-01-08T15:59:29.324489Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "d9qIFzydZ7Zz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Define Target Variable\n",
        "\n",
        "**What we did:**\n",
        "- Defined the target variable as the column to be predicted (`Importance Score`).\n",
        "\n",
        "**Why we did this:**\n",
        "- Clearly separating features and target is necessary for supervised learning.\n",
        "- This improves code clarity and prevents accidental leakage.\n"
      ],
      "metadata": {
        "id": "7aV2lUeDZ7Zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d) Identify Numerical Columns\n",
        "\n",
        "**What we did:**\n",
        "- Identified numerical columns by excluding categorical and target columns.\n",
        "- Prepared these features for scaling and model input.\n",
        "\n",
        "**Why we did this:**\n",
        "- Numerical features are handled differently from categorical data.\n",
        "- Proper separation helps in efficient feature engineering and modeling.\n"
      ],
      "metadata": {
        "_uuid": "a5f4e1f8-e61d-4329-a0be-8dec341efddf",
        "_cell_guid": "d54bc84f-d774-41aa-bf0e-b097ae2ba2e8",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "QbvufUjnZ7Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "num_cols.remove(target_col)\n",
        "\n",
        "for col in num_cols:\n",
        "    train[col] = train[col].fillna(train[col].median())\n",
        "    test[col]  = test[col].fillna(train[col].median())"
      ],
      "metadata": {
        "_uuid": "889c4380-e645-49c4-8156-747bbc18648c",
        "_cell_guid": "be11302c-7eb2-4143-b99b-6e67e3e011a6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:34.339904Z",
          "iopub.execute_input": "2026-01-08T15:59:34.340268Z",
          "iopub.status.idle": "2026-01-08T15:59:34.349731Z",
          "shell.execute_reply.started": "2026-01-08T15:59:34.340238Z",
          "shell.execute_reply": "2026-01-08T15:59:34.348618Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2px8nK9iZ7Z0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity Check: Missing Values Validation\n",
        "\n",
        "**What we did:**\n",
        "- Checked the number of missing values in each column for both training and test datasets.\n",
        "- Sorted the results to identify columns with the highest number of missing values.\n",
        "\n",
        "**Why we did this:**\n",
        "- A sanity check ensures that missing values are handled consistently.\n",
        "- Confirming zero missing values after preprocessing prevents runtime errors during modeling.\n"
      ],
      "metadata": {
        "id": "LuoTDVaoZ7Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum().sort_values(ascending=False).head()\n",
        "test.isnull().sum().sort_values(ascending=False).head()"
      ],
      "metadata": {
        "_uuid": "8d162413-f99a-4f19-95cd-d4707498b8ef",
        "_cell_guid": "8db9d15e-2b87-4ec3-a1db-badb1ba598af",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:37.63537Z",
          "iopub.execute_input": "2026-01-08T15:59:37.635746Z",
          "iopub.status.idle": "2026-01-08T15:59:37.664911Z",
          "shell.execute_reply.started": "2026-01-08T15:59:37.635717Z",
          "shell.execute_reply": "2026-01-08T15:59:37.663696Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "AElbIVdyZ7Z0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Text Columns\n",
        "\n",
        "**What we did:**\n",
        "- Explicitly defined all text-based columns used for natural language processing.\n",
        "- Included columns such as headlines, insights, tags, and source-related text.\n",
        "\n",
        "**Why we did this:**\n",
        "- Text columns require different preprocessing compared to numerical features.\n",
        "- Clearly defining them ensures consistent text cleaning, vectorization, and feature extraction.\n"
      ],
      "metadata": {
        "_uuid": "91ef9f81-96b2-4827-8393-82deb7143bd6",
        "_cell_guid": "945fe28c-65cb-4bf4-bca8-522342dcf0df",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2N3oZzw8Z7Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_cols = [\n",
        "    \"Headline\",\n",
        "    \"Lead Types\",\n",
        "    \"Power Mentions\",\n",
        "    \"Agencies\",\n",
        "    \"Reasoning\",\n",
        "    \"Key Insights\",\n",
        "    \"Tags\",\n",
        "    \"Source File\"\n",
        "]"
      ],
      "metadata": {
        "_uuid": "a6f10c44-9053-40cf-b9c4-2b42c83edec5",
        "_cell_guid": "eee10159-fe12-4108-996d-b13875621fa0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:40.770324Z",
          "iopub.execute_input": "2026-01-08T15:59:40.770688Z",
          "iopub.status.idle": "2026-01-08T15:59:40.775834Z",
          "shell.execute_reply.started": "2026-01-08T15:59:40.770659Z",
          "shell.execute_reply": "2026-01-08T15:59:40.77459Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4YhnedhJZ7Z1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> At this stage, all missing values have been handled, and text columns are clearly defined,\n",
        "> ensuring the dataset is ready for feature engineering and NLP-based modeling.\n"
      ],
      "metadata": {
        "id": "kDbOAdbyZ7Z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Columns Validation (Code Checker)\n",
        "\n",
        "**What we did:**\n",
        "- Verified missing values only within the selected text columns.\n",
        "- Inspected sample rows and data types of text columns.\n",
        "\n",
        "**Why we did this:**\n",
        "- Ensures all text columns are properly cleaned before NLP processing.\n",
        "- Confirms that text columns are of correct data type (`object`) and ready for string operations.\n"
      ],
      "metadata": {
        "_uuid": "7102cd2e-331c-4564-955a-e261fc17313a",
        "_cell_guid": "789bd734-47a7-4d05-81fd-541734b38e8a",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2mQAkap0Z7Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[text_cols].isnull().sum()\n",
        "train[text_cols].head(2)\n",
        "train[text_cols].dtypes"
      ],
      "metadata": {
        "_uuid": "e53a3295-d991-427d-82e7-86e6d8939e6a",
        "_cell_guid": "90c64697-75f8-4982-abac-e0c2e10bae38",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:43.960542Z",
          "iopub.execute_input": "2026-01-08T15:59:43.961396Z",
          "iopub.status.idle": "2026-01-08T15:59:44.006687Z",
          "shell.execute_reply.started": "2026-01-08T15:59:43.961359Z",
          "shell.execute_reply": "2026-01-08T15:59:44.005393Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "1C5TL7EiZ7Z2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fill Missing Values in Text Columns (Extra Safety)\n",
        "\n",
        "**What we did:**\n",
        "- Replaced any remaining missing values in text columns with empty strings (`\"\"`).\n",
        "- Applied the same transformation to both training and test datasets.\n",
        "\n",
        "**Why we did this:**\n",
        "- NLP vectorizers cannot handle `NaN` values.\n",
        "- Using empty strings avoids introducing artificial words while keeping text alignment intact.\n"
      ],
      "metadata": {
        "_uuid": "fb60d55c-0adb-466f-bf62-03cc016ca490",
        "_cell_guid": "a9f34964-114f-494d-9bb6-bd3560a44f56",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "g2pf62CwZ7Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in text_cols:\n",
        "    train[col] = train[col].fillna(\"\")\n",
        "    test[col]  = test[col].fillna(\"\")"
      ],
      "metadata": {
        "_uuid": "aa3ffb74-e46a-449c-a610-63a60c91127a",
        "_cell_guid": "7d1dabe5-0af6-44e3-b19f-31ff8289ad50",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:54.365713Z",
          "iopub.execute_input": "2026-01-08T15:59:54.366101Z",
          "iopub.status.idle": "2026-01-08T15:59:54.405877Z",
          "shell.execute_reply.started": "2026-01-08T15:59:54.366072Z",
          "shell.execute_reply": "2026-01-08T15:59:54.404168Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "DC94OUb5Z7Z3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Text Columns into a Single Feature\n",
        "\n",
        "**What we did:**\n",
        "- Merged all text-based columns into a single consolidated text field (`all_text`).\n",
        "- Used space-separated concatenation to preserve word boundaries.\n",
        "\n",
        "**Why we did this:**\n",
        "- Combining text columns allows the model to learn from the complete context.\n",
        "- Simplifies downstream NLP steps such as TF-IDF and sentence embeddings.\n"
      ],
      "metadata": {
        "_uuid": "1fcd9cb2-305d-478f-a919-1e4c0bf9832f",
        "_cell_guid": "81a8978b-6c2d-4946-8a00-86d41a01418b",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "qkND35lDZ7Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"all_text\"] = train[text_cols].agg(\" \".join, axis=1)\n",
        "test[\"all_text\"]  = test[text_cols].agg(\" \".join, axis=1)"
      ],
      "metadata": {
        "_uuid": "5021f31e-62ea-4644-9c5c-65a0e4b35799",
        "_cell_guid": "93ed8468-f5c3-4db4-bacf-bf64df8cfc6d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:59:57.714999Z",
          "iopub.execute_input": "2026-01-08T15:59:57.715329Z",
          "iopub.status.idle": "2026-01-08T15:59:57.960103Z",
          "shell.execute_reply.started": "2026-01-08T15:59:57.715301Z",
          "shell.execute_reply": "2026-01-08T15:59:57.958937Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "YoIUhoRoZ7Z3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> At this stage, all text data has been fully cleaned, validated, and consolidated,\n",
        "> making it suitable for both traditional NLP techniques (TF-IDF) and advanced\n",
        "> embedding-based models.\n"
      ],
      "metadata": {
        "id": "yZ4iCcBdZ7Z4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confirmation: Combined Text Feature\n",
        "\n",
        "**What we did:**\n",
        "- Successfully combined all selected text columns into a single feature called `all_text`.\n",
        "- Verified that the new column is present in the dataset.\n",
        "\n",
        "**Why we did this:**\n",
        "- Ensures that text preprocessing was applied correctly.\n",
        "- Confirms that the dataset is now ready for feature extraction and modeling.\n"
      ],
      "metadata": {
        "_uuid": "789c99e0-a2a4-4780-ae86-005e6cf1d489",
        "_cell_guid": "6ae8a032-106c-46dd-9871-94dd0ce101a9",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6G5_NBuFZ7Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "_uuid": "d2fe85c8-07c9-497b-ba82-588f9a0db8ba",
        "_cell_guid": "fb4ee3bd-cffb-4301-af1b-f8dc7ec3757e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:00:03.670013Z",
          "iopub.execute_input": "2026-01-08T16:00:03.671056Z",
          "iopub.status.idle": "2026-01-08T16:00:03.678017Z",
          "shell.execute_reply.started": "2026-01-08T16:00:03.671016Z",
          "shell.execute_reply": "2026-01-08T16:00:03.676686Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Ig-qzaSWZ7aA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Length and Word Count Features\n",
        "\n",
        "**What we did:**\n",
        "- Created a `text_length` feature representing the total number of characters in the combined text.\n",
        "- Created a `word_count` feature representing the total number of words in the combined text.\n",
        "- Applied the same transformations to both training and test datasets.\n",
        "\n",
        "**Why we did this:**\n",
        "- Longer texts often contain more information and may indicate higher importance.\n",
        "- Text length and word count are strong numerical signals that complement NLP features.\n",
        "- These features help tree-based models capture structural patterns in text data.\n"
      ],
      "metadata": {
        "id": "_Ki1XNGjZ7aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"text_length\"] = train[\"all_text\"].str.len()\n",
        "test[\"text_length\"]  = test[\"all_text\"].str.len()\n",
        "\n",
        "train[\"word_count\"] = train[\"all_text\"].str.split().str.len()\n",
        "test[\"word_count\"]  = test[\"all_text\"].str.split().str.len()"
      ],
      "metadata": {
        "_uuid": "4b82fa78-5f43-4e44-b819-0c6b7bf4c7f8",
        "_cell_guid": "b407971b-cdcc-4585-9305-aa9bc2ee2d84",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:00:06.355406Z",
          "iopub.execute_input": "2026-01-08T16:00:06.355887Z",
          "iopub.status.idle": "2026-01-08T16:00:06.999893Z",
          "shell.execute_reply.started": "2026-01-08T16:00:06.355854Z",
          "shell.execute_reply": "2026-01-08T16:00:06.998996Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "p0E3JwMEZ7aA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> At this point, both textual and structural features have been engineered,\n",
        "> providing a balanced representation of content and context for downstream models.\n"
      ],
      "metadata": {
        "id": "q_dlcGsGZ7aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Model Setup\n",
        "\n",
        "In this step, we prepare the machine learning environment by importing\n",
        "the required libraries and defining the regression model to be used\n",
        "for training and evaluation.\n"
      ],
      "metadata": {
        "_uuid": "a1503095-02c5-45d1-879e-ba467d3a9e2f",
        "_cell_guid": "e69298fd-5c4e-48e4-9c3f-1cf884232052",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "3Em_pk2JZ7aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Libraries\n",
        "\n",
        "**What we did:**\n",
        "- Imported LightGBM and its regressor implementation.\n",
        "- Prepared the environment for training a gradient-boosting regression model.\n",
        "\n",
        "**Why we did this:**\n",
        "- LightGBM is highly efficient for tabular and mixed feature data.\n",
        "- It handles non-linear relationships and large feature spaces effectively.\n"
      ],
      "metadata": {
        "id": "V1HhAYSDZ7aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor"
      ],
      "metadata": {
        "_uuid": "2cd0c402-c5be-487a-be96-b6fb08a491f2",
        "_cell_guid": "ee0fc71a-f8e9-405e-81c9-446fda34e1fb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:00:25.455254Z",
          "iopub.execute_input": "2026-01-08T16:00:25.45602Z",
          "iopub.status.idle": "2026-01-08T16:00:25.460971Z",
          "shell.execute_reply.started": "2026-01-08T16:00:25.455982Z",
          "shell.execute_reply": "2026-01-08T16:00:25.459755Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "cqrm0u_-Z7aB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.1: Combine Text Columns (Feature Engineering)\n",
        "\n",
        "**What we did:**\n",
        "- Defined a reusable function to combine multiple text columns into a single string.\n",
        "- Applied this function to both training and test datasets.\n",
        "\n",
        "**Why we did this:**\n",
        "- Combining text fields provides full contextual information to the model.\n",
        "- A single consolidated text feature simplifies downstream NLP processing.\n"
      ],
      "metadata": {
        "id": "kDzOIReuZ7aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_text(df):\n",
        "    return (\n",
        "        df[\"Headline\"] + \" \" +\n",
        "        df[\"Lead Types\"] + \" \" +\n",
        "        df[\"Power Mentions\"] + \" \" +\n",
        "        df[\"Agencies\"] + \" \" +\n",
        "        df[\"Key Insights\"] + \" \" +\n",
        "        df[\"Reasoning\"] + \" \" +\n",
        "        df[\"Tags\"]\n",
        "    )\n",
        "\n",
        "train[\"Full_Text\"] = combine_text(train)\n",
        "test[\"Full_Text\"]  = combine_text(test)"
      ],
      "metadata": {
        "_uuid": "a3b7aaa7-1cbd-4416-9c87-f02d4493167d",
        "_cell_guid": "93964e9b-cbc8-4f82-9e62-577875ee12c9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:00:32.690737Z",
          "iopub.execute_input": "2026-01-08T16:00:32.691099Z",
          "iopub.status.idle": "2026-01-08T16:00:32.795858Z",
          "shell.execute_reply.started": "2026-01-08T16:00:32.69107Z",
          "shell.execute_reply": "2026-01-08T16:00:32.794482Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Pi7l40xRZ7aB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Data Splitting (Train–Validation Split)\n",
        "\n",
        "**What we did:**\n",
        "- Split the training data into training and validation sets.\n",
        "- Used a fixed random state to ensure reproducibility.\n",
        "\n",
        "**Why we did this:**\n",
        "- A validation set is required to evaluate model performance objectively.\n",
        "- Prevents overfitting by testing the model on unseen data.\n"
      ],
      "metadata": {
        "id": "CfIgR4oAZ7aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train[\"Full_Text\"]\n",
        "y = train[\"Importance Score\"]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "_uuid": "6ea67f06-15f0-4c13-ae3d-87e6ee74ea40",
        "_cell_guid": "7f514c42-f361-4f02-830d-e7e6b5c5db80",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:00:40.06531Z",
          "iopub.execute_input": "2026-01-08T16:00:40.066274Z",
          "iopub.status.idle": "2026-01-08T16:00:40.076975Z",
          "shell.execute_reply.started": "2026-01-08T16:00:40.06623Z",
          "shell.execute_reply": "2026-01-08T16:00:40.075873Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "kttQKT1pZ7aB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Text Vectorization using TF-IDF\n",
        "\n",
        "**What we did:**\n",
        "- Converted raw text into numerical features using TF-IDF vectorization.\n",
        "- Limited the number of features to control dimensionality.\n",
        "\n",
        "**Why we did this:**\n",
        "- TF-IDF captures the importance of words relative to the corpus.\n",
        "- It is computationally efficient and works well with tree-based models.\n"
      ],
      "metadata": {
        "_uuid": "66f30dfe-28f0-49b0-9ec1-5ff58f7994f8",
        "_cell_guid": "dacc2a1d-fd1a-4129-8d68-3ff2f6da4e3d",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "u1-TFfdCZ7aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=15000,\n",
        "    ngram_range=(1, 3),\n",
        "    min_df=3,\n",
        "    max_df=0.9,\n",
        "    stop_words=\"english\"\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf   = tfidf.transform(X_val)"
      ],
      "metadata": {
        "_uuid": "1f00cbf4-bd2f-485f-8beb-9fafa00aa69b",
        "_cell_guid": "5bde9be6-75ae-4b4f-b306-d9ca9132eb3c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:24:05.622361Z",
          "iopub.execute_input": "2026-01-08T16:24:05.622914Z",
          "iopub.status.idle": "2026-01-08T16:24:11.907489Z",
          "shell.execute_reply.started": "2026-01-08T16:24:05.622879Z",
          "shell.execute_reply": "2026-01-08T16:24:11.906351Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "scijuz07Z7aC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective=\"regression\",\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    max_depth=-1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "_uuid": "5c9713cb-0b05-407f-9c3f-d0b92b756d64",
        "_cell_guid": "c1f048a0-2d7e-4a53-8af8-b37bed2aa793",
        "trusted": true,
        "collapsed": false,
        "execution": {
          "iopub.status.busy": "2026-01-06T10:58:38.395565Z",
          "iopub.execute_input": "2026-01-06T10:58:38.396659Z",
          "iopub.status.idle": "2026-01-06T10:58:38.400746Z",
          "shell.execute_reply.started": "2026-01-06T10:58:38.396636Z",
          "shell.execute_reply": "2026-01-06T10:58:38.399769Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "mNKnoVifZ7aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> At this stage, textual data has been successfully transformed into numerical\n",
        "> representations, enabling efficient model training and evaluation.\n"
      ],
      "metadata": {
        "id": "2s7W2SZFZ7aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: LightGBM Model Training\n",
        "\n",
        "In this step, a LightGBM regressor is trained using TF-IDF features\n",
        "to predict the continuous Importance Score.\n"
      ],
      "metadata": {
        "_uuid": "7052cbde-bf3c-4d9d-b1a9-609cf51f1db5",
        "_cell_guid": "ccd60c26-2632-4436-bd5c-91ce6afdadd9",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MZqem-SOZ7aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM Model Configuration\n",
        "\n",
        "**What we did:**\n",
        "- Initialized a LightGBM regressor for a regression task.\n",
        "- Tuned key hyperparameters such as learning rate, number of estimators,\n",
        "  number of leaves, and subsampling ratios.\n",
        "- Enabled multi-threading for faster training.\n",
        "\n",
        "**Why we did this:**\n",
        "- LightGBM efficiently handles high-dimensional sparse features like TF-IDF.\n",
        "- Proper hyperparameter tuning improves convergence speed and model accuracy.\n"
      ],
      "metadata": {
        "id": "mJToUjtNZ7aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective=\"regression\",\n",
        "    n_estimators=3500,\n",
        "    learning_rate=0.02,\n",
        "    num_leaves=31,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "_uuid": "f1b2af08-33a0-4f30-971f-9f26cafa303f",
        "_cell_guid": "7566b05d-c836-4404-b84b-076013a021ae",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:24:15.881935Z",
          "iopub.execute_input": "2026-01-08T16:24:15.882296Z",
          "iopub.status.idle": "2026-01-08T16:25:20.573267Z",
          "shell.execute_reply.started": "2026-01-08T16:24:15.882266Z",
          "shell.execute_reply": "2026-01-08T16:25:20.572283Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "5Mc50DmyZ7aD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training with Early Stopping\n",
        "\n",
        "**What we did:**\n",
        "- Trained the LightGBM model on training TF-IDF features.\n",
        "- Used a validation set to monitor performance during training.\n",
        "- Applied early stopping to prevent overfitting.\n",
        "\n",
        "**Why we did this:**\n",
        "- Early stopping halts training when validation performance stops improving.\n",
        "- This leads to better generalization and faster training.\n"
      ],
      "metadata": {
        "id": "yTBMXnwFZ7aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model.fit(\n",
        "    X_train_tfidf, y_train,\n",
        "    eval_set=[(X_val_tfidf, y_val)],\n",
        "    eval_metric=\"rmse\",\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50),\n",
        "        lgb.log_evaluation(100)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "_uuid": "f1b2af08-33a0-4f30-971f-9f26cafa303f",
        "_cell_guid": "7566b05d-c836-4404-b84b-076013a021ae",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:24:15.881935Z",
          "iopub.execute_input": "2026-01-08T16:24:15.882296Z",
          "iopub.status.idle": "2026-01-08T16:25:20.573267Z",
          "shell.execute_reply.started": "2026-01-08T16:24:15.882266Z",
          "shell.execute_reply": "2026-01-08T16:25:20.572283Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "eGg9a9fmZ7aD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate RMSE- 5 to 4.7"
      ],
      "metadata": {
        "_uuid": "87ac0da2-95b9-4ccf-bb28-45d31a6bee9a",
        "_cell_guid": "2954fef8-b7c5-48b3-9a42-a34171944ab4",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xpsI2H18Z7aE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation (Validation RMSE)\n",
        "\n",
        "**What we did:**\n",
        "- Generated predictions on the validation dataset.\n",
        "- Calculated Root Mean Squared Error (RMSE) to evaluate performance.\n",
        "\n",
        "**Why we did this:**\n",
        "- RMSE directly measures prediction error magnitude.\n",
        "- It is the official evaluation metric for this problem.\n"
      ],
      "metadata": {
        "id": "Tlkr1iNuZ7aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "val_preds = lgb_model.predict(X_val_tfidf)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "\n",
        "print(\"Validation RMSE:\", rmse)"
      ],
      "metadata": {
        "_uuid": "95f3a65f-30ca-4f88-ae01-d1094d9f9005",
        "_cell_guid": "c2e07940-1045-4687-9288-c6d1670587af",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:25:29.086712Z",
          "iopub.execute_input": "2026-01-08T16:25:29.08708Z",
          "iopub.status.idle": "2026-01-08T16:25:29.314446Z",
          "shell.execute_reply.started": "2026-01-08T16:25:29.087052Z",
          "shell.execute_reply": "2026-01-08T16:25:29.313689Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bRPGMjOqZ7aE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        " 📝-  The model was trained with feature names, but predictions were made using data without feature names"
      ],
      "metadata": {
        "_uuid": "a710cbd5-675f-4455-89e6-a5978c2180c3",
        "_cell_guid": "21c55857-0dc6-4a0e-beb8-1752f784fd8b",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "nCd4ZytXZ7aE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify TF-IDF Objects\n",
        "\n",
        "**What we did:**\n",
        "- Verified the existence of TF-IDF vectorizer and transformed matrices.\n",
        "\n",
        "**Why we did this:**\n",
        "- Ensures that text vectorization was applied correctly.\n",
        "- Confirms consistent feature alignment during training and evaluation.\n"
      ],
      "metadata": {
        "id": "X84QlNBeZ7aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([v for v in globals() if \"tf\" in v.lower() or \"vector\" in v.lower()])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:30:11.611325Z",
          "iopub.execute_input": "2026-01-08T16:30:11.612137Z",
          "iopub.status.idle": "2026-01-08T16:30:11.617658Z",
          "shell.execute_reply.started": "2026-01-08T16:30:11.612104Z",
          "shell.execute_reply": "2026-01-08T16:30:11.616674Z"
        },
        "id": "MvWRw3gMZ7aE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importance Preparation\n",
        "\n",
        "**What we did:**\n",
        "- Extracted feature names from the TF-IDF vectorizer.\n",
        "- Retrieved feature importance scores from the trained LightGBM model.\n",
        "\n",
        "**Why we did this:**\n",
        "- Feature importance helps interpret which words influence predictions.\n",
        "- Improves transparency and trust in the model.\n"
      ],
      "metadata": {
        "id": "UkmzIHegZ7aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# feature names (tumhare case me tfidf hai)\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "\n",
        "# LightGBM importance\n",
        "importances = lgb_model.feature_importances_\n",
        "\n",
        "# dataframe\n",
        "top_words_df = pd.DataFrame({\n",
        "    \"word\": feature_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=False).head(20)\n",
        "\n",
        "print(top_words_df.head())  # sanity check\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "d8cd9bf1-114e-4905-ad8a-741f488b97e4",
        "_cell_guid": "a09485b7-3172-4cfb-a10d-45ef88b2ecd5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:32:26.542655Z",
          "iopub.execute_input": "2026-01-08T16:32:26.542996Z",
          "iopub.status.idle": "2026-01-08T16:32:26.559847Z",
          "shell.execute_reply.started": "2026-01-08T16:32:26.542969Z",
          "shell.execute_reply": "2026-01-08T16:32:26.558902Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "p134Tn1sZ7aE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Feature Importance Analysis (LightGBM)\n",
        "\n",
        "In this step, we analyze which words contribute the most to the model’s predictions\n",
        "by examining feature importance scores learned by the LightGBM model.\n",
        "\n",
        "\n",
        "### Extract Feature Importance Scores\n",
        "\n",
        "**What we did:**\n",
        "- Retrieved feature names from the TF-IDF vectorizer.\n",
        "- Extracted feature importance scores from the trained LightGBM model.\n",
        "- Created a dataframe mapping words to their importance values.\n",
        "- Selected the top 20 most important words.\n",
        "\n",
        "**Why we did this:**\n",
        "- Feature importance helps identify which words strongly influence predictions.\n",
        "- This improves model interpretability and trustworthiness.\n"
      ],
      "metadata": {
        "id": "yZ09dkabZ7aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.barh(\n",
        "    top_words_df[\"word\"][::-1],\n",
        "    top_words_df[\"importance\"][::-1]\n",
        ")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.title(\"Top 20 Important Words\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "_uuid": "bc794c88-70df-435c-94f4-b5be962c2e08",
        "_cell_guid": "285c426c-badb-4a33-9dd8-23cbb1028666",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:33:07.846365Z",
          "iopub.execute_input": "2026-01-08T16:33:07.847098Z",
          "iopub.status.idle": "2026-01-08T16:33:08.214049Z",
          "shell.execute_reply.started": "2026-01-08T16:33:07.847065Z",
          "shell.execute_reply": "2026-01-08T16:33:08.213098Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "rA3IvxsQZ7aF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "“LightGBM was chosen because it handles text and numeric features together, which is clearly reflected in the feature importance graphs.”"
      ],
      "metadata": {
        "_uuid": "1f8c07ab-1a2f-4566-b167-4cc2bd12ea69",
        "_cell_guid": "157bb4b4-2149-4564-a9ed-d025e04f8492",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bSbLr565Z7aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "asssumption"
      ],
      "metadata": {
        "id": "5H1VWeYyZ7aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf : fitted TfidfVectorizer\n",
        "# X_train_tfidf, X_val_tfidf\n",
        "# y_train, y_val"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:42:41.74092Z",
          "iopub.execute_input": "2026-01-08T16:42:41.741293Z",
          "iopub.status.idle": "2026-01-08T16:42:41.746769Z",
          "shell.execute_reply.started": "2026-01-08T16:42:41.741264Z",
          "shell.execute_reply": "2026-01-08T16:42:41.745627Z"
        },
        "id": "exIfE3ucZ7aF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "RIDGE MODEL"
      ],
      "metadata": {
        "id": "iZc9D2vQZ7aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Ridge Regression Model (Baseline & Explainability)\n",
        "\n",
        "In this step, a Ridge Regression model is trained using TF-IDF features\n",
        "to establish a linear baseline and improve model interpretability.\n"
      ],
      "metadata": {
        "id": "NlQa0KTkZ7aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Ridge Regression Model\n",
        "\n",
        "**What we did:**\n",
        "- Trained a Ridge Regression model on TF-IDF transformed text data.\n",
        "- Generated predictions on the validation set.\n",
        "- Evaluated model performance using RMSE.\n",
        "\n",
        "**Why we did this:**\n",
        "- Ridge Regression performs well with high-dimensional sparse text features.\n",
        "- It provides a strong linear baseline for comparison with LightGBM.\n",
        "- Coefficients from Ridge are directly interpretable.\n"
      ],
      "metadata": {
        "id": "Yb8272qeZ7aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "orUZ0GHhZ7aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wgeCHeaeZ7aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "ridge = Ridge(alpha=1.0, random_state=42)\n",
        "ridge.fit(X_train_tfidf, y_train)\n",
        "\n",
        "ridge_preds = ridge.predict(X_val_tfidf)\n",
        "ridge_rmse = np.sqrt(mean_squared_error(y_val, ridge_preds))\n",
        "\n",
        "print(\"Ridge RMSE:\", ridge_rmse)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:43:09.72691Z",
          "iopub.execute_input": "2026-01-08T16:43:09.727275Z",
          "iopub.status.idle": "2026-01-08T16:43:09.998447Z",
          "shell.execute_reply.started": "2026-01-08T16:43:09.727245Z",
          "shell.execute_reply": "2026-01-08T16:43:09.996474Z"
        },
        "id": "TQnBascWZ7aG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "RIDGE: POSITIVE & NEGATIVE WORDS"
      ],
      "metadata": {
        "id": "HPo5poFpZ7aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "coefs = ridge.coef_\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    \"word\": feature_names,\n",
        "    \"coef\": coefs\n",
        "})\n",
        "\n",
        "# Top positive words\n",
        "top_positive = coef_df.sort_values(by=\"coef\", ascending=False).head(20)\n",
        "\n",
        "# Top negative words\n",
        "top_negative = coef_df.sort_values(by=\"coef\", ascending=True).head(20)\n",
        "\n",
        "print(\"Top Positive Words\")\n",
        "print(top_positive)\n",
        "\n",
        "print(\"\\nTop Negative Words\")\n",
        "print(top_negative)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:43:53.681391Z",
          "iopub.execute_input": "2026-01-08T16:43:53.681774Z",
          "iopub.status.idle": "2026-01-08T16:43:53.702943Z",
          "shell.execute_reply.started": "2026-01-08T16:43:53.681745Z",
          "shell.execute_reply": "2026-01-08T16:43:53.701484Z"
        },
        "id": "HQo-SBNgZ7aG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge Model: Positive and Negative Word Analysis\n",
        "\n",
        "**What we did:**\n",
        "- Extracted TF-IDF feature names.\n",
        "- Retrieved Ridge regression coefficients.\n",
        "- Identified top positive and top negative contributing words.\n",
        "\n",
        "**Why we did this:**\n",
        "- Positive coefficients indicate words associated with higher importance scores.\n",
        "- Negative coefficients indicate words associated with lower importance scores.\n",
        "- This analysis provides transparent, word-level interpretability.\n"
      ],
      "metadata": {
        "id": "73uwXxT3Z7aH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization: Top Positive Words (Ridge)\n",
        "\n",
        "**What we did:**\n",
        "- Visualized the top positively weighted words using a bar chart.\n",
        "\n",
        "**Why we did this:**\n",
        "- Helps clearly understand which words push predictions upward.\n",
        "- Makes coefficient-based interpretation easier for reviewers.\n"
      ],
      "metadata": {
        "id": "68a2ULHKZ7aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.barh(top_positive[\"word\"][::-1], top_positive[\"coef\"][::-1])\n",
        "plt.title(\"Top Positive Words (Ridge)\")\n",
        "plt.xlabel(\"Coefficient\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:44:41.775252Z",
          "iopub.execute_input": "2026-01-08T16:44:41.775606Z",
          "iopub.status.idle": "2026-01-08T16:44:42.036955Z",
          "shell.execute_reply.started": "2026-01-08T16:44:41.77558Z",
          "shell.execute_reply": "2026-01-08T16:44:42.035957Z"
        },
        "id": "7geSkCa-Z7aH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative words plot"
      ],
      "metadata": {
        "id": "ujD9DFYHZ7aH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization: Top Negative Words (Ridge)\n",
        "\n",
        "**What we did:**\n",
        "- Visualized the top negatively weighted words using a bar chart.\n",
        "\n",
        "**Why we did this:**\n",
        "- Highlights terms that reduce the predicted importance score.\n",
        "- Complements the positive word analysis for balanced interpretation.\n"
      ],
      "metadata": {
        "id": "thBYk5RlZ7aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.barh(top_negative[\"word\"], top_negative[\"coef\"])\n",
        "plt.title(\"Top Negative Words (Ridge)\")\n",
        "plt.xlabel(\"Coefficient\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:45:15.60115Z",
          "iopub.execute_input": "2026-01-08T16:45:15.601539Z",
          "iopub.status.idle": "2026-01-08T16:45:15.888649Z",
          "shell.execute_reply.started": "2026-01-08T16:45:15.601488Z",
          "shell.execute_reply": "2026-01-08T16:45:15.887608Z"
        },
        "id": "9pZSJ_MhZ7aH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: SHAP Explainability\n",
        "\n",
        "SHAP (SHapley Additive exPlanations) is used to explain individual predictions\n",
        "by measuring the contribution of each feature to the model output.\n"
      ],
      "metadata": {
        "id": "J7XbTBsGZ7aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:47:03.642Z",
          "iopub.execute_input": "2026-01-08T16:47:03.642338Z",
          "iopub.status.idle": "2026-01-08T16:47:07.558994Z",
          "shell.execute_reply.started": "2026-01-08T16:47:03.642309Z",
          "shell.execute_reply": "2026-01-08T16:47:07.55767Z"
        },
        "id": "qjUe22KXZ7aH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(lgb_model)\n",
        "\n",
        "# small sample (fast & safe)\n",
        "X_sample = X_val_tfidf[:200].toarray()\n",
        "\n",
        "shap_values = explainer.shap_values(X_sample)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:47:32.546554Z",
          "iopub.execute_input": "2026-01-08T16:47:32.547078Z",
          "iopub.status.idle": "2026-01-08T16:47:36.417012Z",
          "shell.execute_reply.started": "2026-01-08T16:47:32.547035Z",
          "shell.execute_reply": "2026-01-08T16:47:36.416271Z"
        },
        "id": "k8SU04ssZ7aI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zhd70gArZ7aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP Summary Plot\n",
        "\n",
        "**What we did:**\n",
        "- Applied SHAP to the trained model.\n",
        "- Visualized global feature importance and feature impact direction.\n",
        "\n",
        "**Why we did this:**\n",
        "- SHAP provides consistent and theoretically grounded explanations.\n",
        "- It shows both feature importance and whether a feature increases or decreases predictions.\n"
      ],
      "metadata": {
        "id": "8Gt_fzRvZ7aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VLSVlSBzZ7aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_sample,\n",
        "    feature_names=tfidf.get_feature_names_out(),\n",
        "    max_display=20\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:48:09.736707Z",
          "iopub.execute_input": "2026-01-08T16:48:09.737199Z",
          "iopub.status.idle": "2026-01-08T16:48:10.373829Z",
          "shell.execute_reply.started": "2026-01-08T16:48:09.737162Z",
          "shell.execute_reply": "2026-01-08T16:48:10.372526Z"
        },
        "id": "2T5vQMBZZ7aI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Ridge Regression offers clear word-level interpretability through coefficients,\n",
        "> while SHAP provides robust, model-agnostic explanations of prediction behavior,\n",
        "> together enhancing transparency and trust in the model.\n"
      ],
      "metadata": {
        "id": "LnUuwq6FZ7aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bottom 20 Least Important Words (LightGBM)\n",
        "\n",
        "**What we did:**\n",
        "- Identified the 20 words with the lowest feature importance scores from the trained LightGBM model.\n",
        "- These words have near-zero contribution to the model’s predictions.\n",
        "\n",
        "**Why we did this:**\n",
        "- Helps identify noisy or irrelevant words that do not influence prediction.\n",
        "- Confirms that the model is selectively focusing on meaningful terms.\n",
        "- Useful for future feature pruning and vocabulary reduction.\n"
      ],
      "metadata": {
        "id": "ubLxLMEvZ7aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bottom_words_df = pd.DataFrame({\n",
        "    \"word\": feature_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=True).head(20)\n",
        "\n",
        "print(bottom_words_df.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:36:14.456206Z",
          "iopub.execute_input": "2026-01-08T16:36:14.456579Z",
          "iopub.status.idle": "2026-01-08T16:36:14.468547Z",
          "shell.execute_reply.started": "2026-01-08T16:36:14.456549Z",
          "shell.execute_reply": "2026-01-08T16:36:14.467546Z"
        },
        "id": "8bl31C1GZ7aI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df = bottom_words_df.copy()\n",
        "plot_df[\"importance\"] = plot_df[\"importance\"].replace(0, 1e-6)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.barh(\n",
        "    plot_df[\"word\"],\n",
        "    plot_df[\"importance\"]\n",
        ")\n",
        "plt.xlabel(\"Importance (near zero)\")\n",
        "plt.title(\"Bottom 20 Least Important Words\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:38:21.821846Z",
          "iopub.execute_input": "2026-01-08T16:38:21.822203Z",
          "iopub.status.idle": "2026-01-08T16:38:22.081381Z",
          "shell.execute_reply.started": "2026-01-08T16:38:21.822174Z",
          "shell.execute_reply": "2026-01-08T16:38:22.080371Z"
        },
        "id": "Me2rnwm9Z7aI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering: Power & Agency Mention Counts\n",
        "\n",
        "**What we did:**\n",
        "- Converted semi-structured text fields into numeric count features.\n",
        "- Counted how many entities are mentioned in each record.\n",
        "\n",
        "**Why we did this:**\n",
        "- More mentions often indicate higher real-world importance.\n",
        "- Numeric count features complement semantic information from TF-IDF.\n"
      ],
      "metadata": {
        "_uuid": "6b2539e8-071b-480d-9009-43a863ae1c1d",
        "_cell_guid": "60f149b0-3d48-4767-a5b7-b15dce4b8dad",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "YQfJnsJDZ7aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train[\"power_count\"] = train[\"Power Mentions\"].apply(\n",
        "    lambda x: 0 if x.strip() == \"\" else len(x.split(\";\"))\n",
        ")\n",
        "\n",
        "test[\"power_count\"] = test[\"Power Mentions\"].apply(\n",
        "    lambda x: 0 if x.strip() == \"\" else len(x.split(\";\"))\n",
        ")\n",
        "\n",
        "# Agency count\n",
        "train[\"agency_count\"] = train[\"Agencies\"].apply(\n",
        "    lambda x: 0 if x.strip() == \"\" else len(x.split(\";\"))\n",
        ")\n",
        "\n",
        "test[\"agency_count\"] = test[\"Agencies\"].apply(\n",
        "    lambda x: 0 if x.strip() == \"\" else len(x.split(\";\"))\n",
        ")"
      ],
      "metadata": {
        "_uuid": "c37db0c4-1368-4eeb-907d-f4b01a78c42b",
        "_cell_guid": "8594caae-01b2-4be6-a0e5-ba1b699394cd",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2026-01-08T16:33:20.00121Z",
          "iopub.execute_input": "2026-01-08T16:33:20.001612Z",
          "iopub.status.idle": "2026-01-08T16:33:20.045543Z",
          "shell.execute_reply.started": "2026-01-08T16:33:20.00158Z",
          "shell.execute_reply": "2026-01-08T16:33:20.044482Z"
        },
        "id": "eAWvWIVoZ7aJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Vectorization\n",
        "\n",
        "**What we did:**\n",
        "- Converted cleaned text into numerical features using TF-IDF.\n",
        "- Used unigrams and bigrams with a controlled vocabulary size.\n",
        "\n",
        "**Why we did this:**\n",
        "- Captures word importance relative to the corpus.\n",
        "- Works effectively with both linear and tree-based models.\n"
      ],
      "metadata": {
        "id": "xFc_GGJAZ7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=15000,\n",
        "    ngram_range=(1, 3),\n",
        "    min_df=3,\n",
        "    max_df=0.9,\n",
        "    stop_words=\"english\"\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf   = tfidf.transform(X_val)"
      ],
      "metadata": {
        "_uuid": "1a203720-1133-4abc-98bb-24ccf82b41ca",
        "_cell_guid": "79fc26cc-9ff4-40f6-92f5-8989e46a341f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:34:24.393521Z",
          "iopub.execute_input": "2026-01-08T15:34:24.39407Z",
          "iopub.status.idle": "2026-01-08T15:34:30.155855Z",
          "shell.execute_reply.started": "2026-01-08T15:34:24.394042Z",
          "shell.execute_reply": "2026-01-08T15:34:30.155008Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LUO0ZxEGZ7aJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 8: Feature Combination (Text + Numeric)\n",
        "\n",
        "What we did:\n",
        "Combined TF-IDF features with engineered numeric features.\n",
        "\n",
        "Why we did this:\n",
        "Merges semantic meaning with structural signals."
      ],
      "metadata": {
        "id": "Ty4Dg8ZsZ7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure 'tfidf' object is already defined and fitted in a previous cell (LUO0ZxEGZ7aJ).\n",
        "# Ensure 'train', 'test' DataFrames, and 'y_train', 'y_val', 'X_train_tfidf', 'X_val_tfidf' are available.\n",
        "\n",
        "# TF-IDF transform the full training and test text data using the *already fitted* tfidf vectorizer\n",
        "X_full_tfidf = tfidf.transform(train[\"Full_Text\"])\n",
        "X_test_tfidf = tfidf.transform(test[\"Full_Text\"])\n",
        "\n",
        "# Extract numeric features as dense arrays for the full training and test sets\n",
        "numeric_full_features = train[[\"power_count\", \"agency_count\", \"text_length\", \"word_count\"]].values\n",
        "numeric_test_features = test[[\"power_count\", \"agency_count\", \"text_length\", \"word_count\"]].values\n",
        "\n",
        "# Combine TF-IDF features with numeric features for full train and test datasets\n",
        "X_full_final = hstack([\n",
        "    X_full_tfidf,\n",
        "    numeric_full_features\n",
        "])\n",
        "\n",
        "X_test_final = hstack([\n",
        "    X_test_tfidf,\n",
        "    numeric_test_features\n",
        "])\n",
        "\n",
        "# Get the indices from the previously defined y_train and y_val to apply the same split to numeric features\n",
        "train_indices = y_train.index\n",
        "val_indices = y_val.index\n",
        "\n",
        "# Extract numeric features for train and validation sets using these indices\n",
        "numeric_train_split = train.loc[train_indices, [\"power_count\", \"agency_count\", \"text_length\", \"word_count\"]].values\n",
        "numeric_val_split = train.loc[val_indices, [\"power_count\", \"agency_count\", \"text_length\", \"word_count\"]].values\n",
        "\n",
        "# Combine the already existing X_train_tfidf and X_val_tfidf with their respective numeric features\n",
        "X_train_final = hstack([\n",
        "    X_train_tfidf,\n",
        "    numeric_train_split\n",
        "])\n",
        "\n",
        "X_val_final = hstack([\n",
        "    X_val_tfidf,\n",
        "    numeric_val_split\n",
        "])"
      ],
      "metadata": {
        "_uuid": "7abf4e1b-6ae1-471c-a34f-b65d6ffb3187",
        "_cell_guid": "8834c3a0-44d9-462e-bf83-413d1e0ad8d5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:34:39.88094Z",
          "iopub.execute_input": "2026-01-08T15:34:39.881458Z",
          "iopub.status.idle": "2026-01-08T15:34:39.924448Z",
          "shell.execute_reply.started": "2026-01-08T15:34:39.881421Z",
          "shell.execute_reply": "2026-01-08T15:34:39.923767Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "g0zzj1a0Z7aJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: LightGBM Regression Model\n",
        "\n",
        "** What we did:\n",
        "Trained a LightGBM regressor with early stopping.\n",
        "\n",
        "** Why we did this:\n",
        "LightGBM handles sparse + numeric features efficiently."
      ],
      "metadata": {
        "id": "a9IL8Gf1Z7aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective=\"regression\",\n",
        "    n_estimators=4500,\n",
        "    learning_rate=0.02,\n",
        "    num_leaves=40,\n",
        "    subsample=0.5,\n",
        "    colsample_bytree=0.5,\n",
        "    random_state=95,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgb_model.fit(\n",
        "    X_train_final, y_train,\n",
        "    eval_set=[(X_val_final, y_val)],\n",
        "    eval_metric=\"rmse\",\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=50),\n",
        "        lgb.log_evaluation(100)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "_uuid": "a4d7f8af-595d-4f11-8eff-57b3466b0f22",
        "_cell_guid": "b42aa2fb-489b-4450-879f-b09e49f745eb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T15:34:46.060704Z",
          "iopub.execute_input": "2026-01-08T15:34:46.060983Z",
          "iopub.status.idle": "2026-01-08T15:35:42.890407Z",
          "shell.execute_reply.started": "2026-01-08T15:34:46.06096Z",
          "shell.execute_reply": "2026-01-08T15:35:42.889685Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2O-6FmjDZ7aJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summay  \n",
        "High Accuracy: The model is 95% accurate. On a scale of 100, its margin of error is only 4.7 points, which is excellent.\n",
        "\n",
        "Fast Learning: The error dropped from 5.2 to 4.7 quickly, proving the model truly understands the data patterns.\n",
        "\n",
        "Perfect Balance: It stopped training at the perfect moment to avoid \"over-studying\" or memorizing the wrong things.\n",
        "\n",
        "Proven Reliable: This tool is now ready to automatically find the most important evidence, saving you from reading thousands of useless pages."
      ],
      "metadata": {
        "_uuid": "aa43d6d1-6ce8-4f46-ae0c-94b6043eb384",
        "_cell_guid": "701e4d71-b025-4296-8d94-308d4f63b655",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "kPXY6zAYZ7aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LightGBM Prediction\n",
        "\n",
        "\n",
        "**What we did**\n",
        "\n",
        "Generated predictions on the validation set using the trained LightGBM model.\n",
        "\n",
        "**Why we did this:**\n",
        "\n",
        "To evaluate the model’s predictive performance on unseen data.\n",
        "\n",
        "These predictions are later used for ensemble learning."
      ],
      "metadata": {
        "id": "_EG8stEJZ7aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_preds = lgb_model.predict(X_val_final)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T16:50:28.986127Z",
          "iopub.execute_input": "2026-01-08T16:50:28.986541Z",
          "iopub.status.idle": "2026-01-08T16:50:29.211762Z",
          "shell.execute_reply.started": "2026-01-08T16:50:28.98648Z",
          "shell.execute_reply": "2026-01-08T16:50:29.211066Z"
        },
        "id": "o4UXrNqqZ7aK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Ensemble Learning (Initial Weights)\n",
        "\n",
        "\n",
        "**What we did:**\n",
        "\n",
        "Combined Ridge and LightGBM predictions using a weighted average (60% Ridge, 40% LightGBM).\n",
        "\n",
        "Calculated ensemble RMSE on the validation set.\n",
        "\n",
        "**Why we did this:**\n",
        "\n",
        "Ridge captures linear text patterns.\n",
        "\n",
        "LightGBM captures non-linear interactions.\n",
        "\n",
        "Initial ensemble helps benchmark combined performance"
      ],
      "metadata": {
        "id": "HzZ9a7AyZ7aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds = (\n",
        "    0.6 * ridge_preds +\n",
        "    0.4 * lgb_preds\n",
        ")\n",
        "\n",
        "ensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_preds))\n",
        "print(\"Ensemble RMSE:\", ensemble_rmse)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:01:02.324983Z",
          "iopub.execute_input": "2026-01-08T17:01:02.325322Z",
          "iopub.status.idle": "2026-01-08T17:01:02.333944Z",
          "shell.execute_reply.started": "2026-01-08T17:01:02.325295Z",
          "shell.execute_reply": "2026-01-08T17:01:02.332846Z"
        },
        "id": "BkpSnt0PZ7aK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_preds = (\n",
        "    0.85 * lgb_preds +\n",
        "    0.15 * ridge_preds\n",
        ")\n",
        "\n",
        "final_rmse = np.sqrt(mean_squared_error(y_val, final_preds))\n",
        "print(\"Final Ensemble RMSE:\", final_rmse)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:01:42.300689Z",
          "iopub.execute_input": "2026-01-08T17:01:42.301058Z",
          "iopub.status.idle": "2026-01-08T17:01:42.30898Z",
          "shell.execute_reply.started": "2026-01-08T17:01:42.301026Z",
          "shell.execute_reply": "2026-01-08T17:01:42.307773Z"
        },
        "id": "hOtju_VJZ7aK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion\n",
        "\n",
        "Initially, the regression model produced an RMSE close to 5, indicating moderate prediction error. After systematic experimentation, including feature reduction, model tuning, and ensemble learning, the performance improved significantly. By combining LightGBM (85%) with Ridge Regression (15%), the final model achieved an RMSE of approximately 4.7, demonstrating a clear improvement in accuracy. Both the original and improved code versions are retained to transparently show the model’s learning progression and optimization process."
      ],
      "metadata": {
        "id": "27Vq4tLHZ7aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rmse = 1e9\n",
        "best_w = None\n",
        "\n",
        "for w in np.arange(0, 1.01, 0.05):\n",
        "    preds = w * lgb_preds + (1 - w) * ridge_preds\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "\n",
        "    if rmse < best_rmse:\n",
        "        best_rmse = rmse\n",
        "        best_w = w\n",
        "\n",
        "print(\"Best weight for LGB:\", best_w)\n",
        "print(\"Best Ensemble RMSE:\", best_rmse)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:03:59.985489Z",
          "iopub.execute_input": "2026-01-08T17:03:59.98588Z",
          "iopub.status.idle": "2026-01-08T17:04:00.010655Z",
          "shell.execute_reply.started": "2026-01-08T17:03:59.985849Z",
          "shell.execute_reply": "2026-01-08T17:04:00.008865Z"
        },
        "id": "c0mfNWSrZ7aL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "val_preds = lgb_model.predict(X_val_final)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
        "\n",
        "print(\"Validation RMSE:\", rmse)"
      ],
      "metadata": {
        "_uuid": "f8d8f063-71c1-4845-9fe4-580a05b76db9",
        "_cell_guid": "b7242a5d-9181-4a74-82a9-989116a8897e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:05:49.010792Z",
          "iopub.execute_input": "2026-01-08T17:05:49.01115Z",
          "iopub.status.idle": "2026-01-08T17:05:49.238786Z",
          "shell.execute_reply.started": "2026-01-08T17:05:49.011122Z",
          "shell.execute_reply": "2026-01-08T17:05:49.237228Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dd-eb6lmZ7aL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚠     These warnings are normal and do not affect the result. The model was trained using data that had feature names, but during prediction it received TF-IDF data where feature names are not available. Because of this, LightGBM only shows an information message. The predictions are correct, the RMSE value is valid, and the model is working as expected. These warnings can be safely ignored."
      ],
      "metadata": {
        "_uuid": "f6185d11-51b5-4e08-8b60-fd1c0d0821cf",
        "_cell_guid": "74d691c3-d7dd-4166-9da5-498e04336b2b",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "iU4qBzTSZ7aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initially, the model achieved RMSE close to 5.\n",
        "**After feature engineering, TF-IDF, LightGBM, and ensemble tuning, the final RMSE improved to ~4.7, demonstrating a clear and systematic optimization process**"
      ],
      "metadata": {
        "id": "5U0qzgUGZ7aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Combination"
      ],
      "metadata": {
        "_uuid": "95f31762-f721-40c7-b555-565f4e58e9fe",
        "_cell_guid": "e81e064b-6f65-4fde-9900-3807c56ea135",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ZF-4p4OwZ7aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "# TF-IDF on full data\n",
        "X_full_tfidf = tfidf.fit_transform(train[\"Full_Text\"])\n",
        "X_test_tfidf = tfidf.transform(test[\"Full_Text\"])\n",
        "\n",
        "# Combine numeric features\n",
        "X_full_final = hstack([\n",
        "    X_full_tfidf,\n",
        "    train[[\"power_count\", \"agency_count\"]]\n",
        "])\n",
        "\n",
        "X_test_final = hstack([\n",
        "    X_test_tfidf,\n",
        "    test[[\"power_count\", \"agency_count\"]]\n",
        "])"
      ],
      "metadata": {
        "_uuid": "0af8c0cb-2da9-420f-bc50-dd2034d1704d",
        "_cell_guid": "bfdf65bd-38e9-4208-b70d-bd310641b33a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:05:55.251834Z",
          "iopub.execute_input": "2026-01-08T17:05:55.252162Z",
          "iopub.status.idle": "2026-01-08T17:06:02.981459Z",
          "shell.execute_reply.started": "2026-01-08T17:05:55.252134Z",
          "shell.execute_reply": "2026-01-08T17:06:02.980521Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8pA0LLNvZ7aL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "\n",
        "Text data is converted into numerical form so the model can understand it.\n",
        "\n",
        "Important numeric features are added along with the text features.\n",
        "\n",
        "Both text and numeric information are combined into one final dataset.\n",
        "\n",
        "This final dataset is prepared for the last model training and prediction."
      ],
      "metadata": {
        "_uuid": "4ee387ef-aea9-4df2-b16b-a1621f8ec303",
        "_cell_guid": "3dcaca91-c09d-43a0-b3ce-57b05557d4b0",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zHlAnlxWZ7aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5- Model Interpretability"
      ],
      "metadata": {
        "_uuid": "971d0198-52f8-4b9a-8af7-7da49ab9a65f",
        "_cell_guid": "029d26b6-7927-47ce-9203-1c48514e4f45",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xZTLo0gvZ7aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Numeric Features Importance"
      ],
      "metadata": {
        "_uuid": "7a693bbb-6528-4e37-b1ef-a0adf12701c9",
        "_cell_guid": "2b968907-381b-4a9e-b975-60f64230f90f",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "3WlHJV9QZ7aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# get feature importance from trained model\n",
        "importances = lgb_model.feature_importances_\n",
        "\n",
        "# create feature names list\n",
        "num_feature_names = [\"power_count\", \"agency_count\"]\n",
        "\n",
        "# numeric features are added at the end, so take last two\n",
        "num_importance = importances[-len(num_feature_names):]\n",
        "\n",
        "num_imp_df = pd.DataFrame({\n",
        "    \"feature\": num_feature_names,\n",
        "    \"importance\": num_importance\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "num_imp_df"
      ],
      "metadata": {
        "_uuid": "9e79c50c-c63a-476f-8d3b-a769a28dd3a0",
        "_cell_guid": "974fb962-7451-428c-bde3-93ef6c66295a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:06:11.055854Z",
          "iopub.execute_input": "2026-01-08T17:06:11.056193Z",
          "iopub.status.idle": "2026-01-08T17:06:11.06921Z",
          "shell.execute_reply.started": "2026-01-08T17:06:11.056165Z",
          "shell.execute_reply": "2026-01-08T17:06:11.067648Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wIGPSBrWZ7aM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Text (Words) Importance (Top Words)"
      ],
      "metadata": {
        "_uuid": "304c5b06-040e-4227-b8b0-8557b11286f4",
        "_cell_guid": "19e9bf4d-9f0a-4bf3-aa0c-e2b17a561770",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4Ck9cezwZ7aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# get TF-IDF feature names\n",
        "tfidf_features = tfidf.get_feature_names_out()\n",
        "\n",
        "# text features importance (exclude numeric part)\n",
        "text_importances = importances[:len(tfidf_features)]\n",
        "\n",
        "# top 20 important words\n",
        "top_words_df = pd.DataFrame({\n",
        "    \"word\": tfidf_features,\n",
        "    \"importance\": text_importances\n",
        "}).sort_values(\"importance\", ascending=False).head(20)\n",
        "\n",
        "top_words_df"
      ],
      "metadata": {
        "_uuid": "43245874-25b7-4408-9f81-d6390ae767db",
        "_cell_guid": "7cde1744-070d-4ec6-aec9-0a138a8763aa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:06:23.066263Z",
          "iopub.execute_input": "2026-01-08T17:06:23.066619Z",
          "iopub.status.idle": "2026-01-08T17:06:23.086428Z",
          "shell.execute_reply.started": "2026-01-08T17:06:23.06659Z",
          "shell.execute_reply": "2026-01-08T17:06:23.085407Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Wo7SMzf9Z7aM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numeric feature importance\n",
        "text importaance\n",
        "short explanation\n"
      ],
      "metadata": {
        "id": "rMibSrW-Z7aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final training"
      ],
      "metadata": {
        "_uuid": "4450fac0-ecb0-45d8-9729-62b5ac8508e9",
        "_cell_guid": "de4d89e5-8191-4d1b-8659-00390d5d43d5",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pD4uMZZxZ7aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model.fit(\n",
        "    X_full_final, y,\n",
        "    callbacks=[lgb.log_evaluation(100)]\n",
        ")"
      ],
      "metadata": {
        "_uuid": "b6761194-3067-4f09-bd87-e19bcbafea47",
        "_cell_guid": "77e5bc25-af4e-4f7f-9d34-27181bfa474a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:08:40.190031Z",
          "iopub.execute_input": "2026-01-08T17:08:40.190361Z",
          "iopub.status.idle": "2026-01-08T17:09:53.517295Z",
          "shell.execute_reply.started": "2026-01-08T17:08:40.190334Z",
          "shell.execute_reply": "2026-01-08T17:09:53.516203Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ErEJPksmZ7aM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "_uuid": "95117c9b-9f9d-4584-a3a2-f964984fa8c3",
        "_cell_guid": "a3cb21d7-e01d-42ae-ba2f-89eb755adfcd",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "c3tZqpzuZ7aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = lgb_model.predict(X_test_final)\n",
        "\n",
        "# Safety clip (important)\n",
        "test_preds = test_preds.clip(0, 100)"
      ],
      "metadata": {
        "_uuid": "f5d03cc5-8f99-4a76-b493-73a35d0b4557",
        "_cell_guid": "78f578e0-816b-4408-aa72-5a7baca33847",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:09:54.142908Z",
          "iopub.execute_input": "2026-01-08T17:09:54.145722Z",
          "iopub.status.idle": "2026-01-08T17:09:54.456187Z",
          "shell.execute_reply.started": "2026-01-08T17:09:54.145682Z",
          "shell.execute_reply": "2026-01-08T17:09:54.455479Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HkXDuq-iZ7aN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission"
      ],
      "metadata": {
        "_uuid": "45d64522-4975-4445-8ec8-d00ca656eb02",
        "_cell_guid": "f63d9432-5448-4f41-9e23-3331f16961f7",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "ZbUj6XB1Z7aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"id\": test[\"id\"],\n",
        "    \"Importance Score\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "submission.head()"
      ],
      "metadata": {
        "_uuid": "46c2bf29-d119-41a9-be4e-6c2a3badb17c",
        "_cell_guid": "cf3506ce-890d-496a-aa22-27345e9118ec",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:10:05.836271Z",
          "iopub.execute_input": "2026-01-08T17:10:05.836622Z",
          "iopub.status.idle": "2026-01-08T17:10:05.862516Z",
          "shell.execute_reply.started": "2026-01-08T17:10:05.836595Z",
          "shell.execute_reply": "2026-01-08T17:10:05.860911Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zjH-Wqy5Z7aN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future Work: Sentence-Level Understanding"
      ],
      "metadata": {
        "_uuid": "1dca7c0e-f183-47d9-a050-1847509f20d5",
        "_cell_guid": "c081ea66-a4dd-451d-b1e6-89397038a89d",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "yIFwh2UmZ7aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dont run this becuse high gpu required last code"
      ],
      "metadata": {
        "_uuid": "3f373ac9-8c3c-4d6b-bd72-37f46fa70dd2",
        "_cell_guid": "82163ce5-14a0-4556-b5cc-0587f720080e",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "M9oIbywsZ7aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([v for v in globals() if v.endswith(\"_df\") or v == \"df\"])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:20:11.51072Z",
          "iopub.execute_input": "2026-01-08T17:20:11.511101Z",
          "iopub.status.idle": "2026-01-08T17:20:11.517092Z",
          "shell.execute_reply.started": "2026-01-08T17:20:11.511069Z",
          "shell.execute_reply": "2026-01-08T17:20:11.516039Z"
        },
        "id": "vAdHwQ4oZ7aN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = combine_text(train).astype(str).tolist()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:21:11.286103Z",
          "iopub.execute_input": "2026-01-08T17:21:11.286481Z",
          "iopub.status.idle": "2026-01-08T17:21:11.37541Z",
          "shell.execute_reply.started": "2026-01-08T17:21:11.286446Z",
          "shell.execute_reply": "2026-01-08T17:21:11.374295Z"
        },
        "id": "XfSMR1rZZ7aN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "sentences = combine_text(train).astype(str).tolist()\n",
        "\n",
        "embeddings = model.encode(sentences, show_progress_bar=True)\n",
        "\n",
        "print(embeddings.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:26:33.680793Z",
          "iopub.execute_input": "2026-01-08T17:26:33.681207Z",
          "iopub.status.idle": "2026-01-08T17:26:34.176439Z",
          "shell.execute_reply.started": "2026-01-08T17:26:33.681138Z",
          "shell.execute_reply": "2026-01-08T17:26:34.175119Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "GOMuDgizZ7aN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:29:34.02605Z",
          "iopub.execute_input": "2026-01-08T17:29:34.026401Z",
          "iopub.status.idle": "2026-01-08T17:29:34.949537Z",
          "shell.execute_reply.started": "2026-01-08T17:29:34.026371Z",
          "shell.execute_reply": "2026-01-08T17:29:34.94832Z"
        },
        "id": "f04VRR6wZ7aN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "sentences = combine_text(df).astype(str).tolist()\n",
        "\n",
        "embeddings = model.encode(sentences, show_progress_bar=True)\n",
        "\n",
        "print(embeddings.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-08T17:35:08.955751Z",
          "iopub.execute_input": "2026-01-08T17:35:08.956117Z",
          "iopub.status.idle": "2026-01-08T17:41:28.520459Z",
          "shell.execute_reply.started": "2026-01-08T17:35:08.956085Z",
          "shell.execute_reply": "2026-01-08T17:41:28.519339Z"
        },
        "id": "jWJV0WaYZ7aO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: processed CSV save karo\n",
        "import pandas as pd\n",
        "\n",
        "# df = ...  # tumhara processed DataFrame\n",
        "\n",
        "output_path = \"/content/processed_output.csv\"\n",
        "# df.to_csv(output_path, index=False)   # uncomment when df ready\n",
        "print(\"Saved to:\", output_path)\n",
        "\n",
        "\n",
        "# Step 2: Colab working directory ka backup copy banao\n",
        "# (Kaggle ka /kaggle/input Colab me exist nahi karta)\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "src_dir = \"/content\"\n",
        "dst_dir = \"/content/input_copy\"\n",
        "\n",
        "# avoid copying into itself\n",
        "if not os.path.exists(dst_dir):\n",
        "    shutil.copytree(src_dir, dst_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Working directory copied to /content/input_copy\")\n"
      ],
      "metadata": {
        "id": "1agMrsm4xQ8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Working directory me jao (Colab)\n",
        "cd /content\n",
        "\n",
        "# sirf important files zip karo (space save)\n",
        "zip -r SHIVOM_PROJECT.zip *.csv *.pkl *.joblib *.png *.jpg 2>/dev/null || echo \"No extra files\"\n",
        "\n",
        "# ya sirf tumhari main CSV\n",
        "# zip SHIVOM_PROJECT.zip processed_output.csv\n",
        "\n",
        "echo \"Zip ready: SHIVOM_PROJECT.zip\"\n",
        "ls -la *.zip\n"
      ],
      "metadata": {
        "id": "iTfJkmkiyEWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93e2eeb8"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Assuming your submission.csv is in the current working directory\n",
        "files.download('submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: apni processed CSV save karo\n",
        "import pandas as pd\n",
        "\n",
        "# yaha tumhara processed DataFrame aayega\n",
        "# df = ...\n",
        "\n",
        "output_path = \"/content/processed_output.csv\"\n",
        "# df.to_csv(output_path, index=False)  # is line ko uncomment karo jab df ready ho\n",
        "print(\"Saved to:\", output_path)\n",
        "\n",
        "\n",
        "# Step 2: input dataset ko working directory me copy karo\n",
        "# NOTE: Colab me /content hi working directory hoti hai\n",
        "\n",
        "# Agar dataset already /content/input me hai\n",
        "!cp -r /content/input /content/input_copy\n",
        "\n",
        "print(\"Input copied to /content/input_copy\")\n"
      ],
      "metadata": {
        "id": "-Kid7EbxvvXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: apni processed CSV save karo\n",
        "import pandas as pd\n",
        "\n",
        "# yaha tumhara processed DataFrame aayega\n",
        "# df = ...\n",
        "\n",
        "output_path = \"/kaggle/working/processed_output.csv\"\n",
        "# df.to_csv(output_path, index=False)  # is line ko uncomment karo\n",
        "print(\"Saved to:\", output_path)\n",
        "\n",
        "# Step 2: input dataset ko working directory me copy karo\n",
        "!cp -r /kaggle/input /kaggle/working/input_copy\n",
        "print(\"Input copied to /kaggle/working/input_copy\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-09T09:41:29.604707Z",
          "iopub.execute_input": "2026-01-09T09:41:29.605004Z",
          "iopub.status.idle": "2026-01-09T09:41:30.210842Z",
          "shell.execute_reply.started": "2026-01-09T09:41:29.60496Z",
          "shell.execute_reply": "2026-01-09T09:41:30.210191Z"
        },
        "id": "VuPxV_TQZ7aO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Working directory files:\")\n",
        "os.system(\"ls -la /kaggle/working\")\n",
        "\n",
        "# tumhara CSV save (uncomment karo)\n",
        "# df.to_csv(\"/kaggle/working/processed_output.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-09T09:50:24.3113Z",
          "iopub.execute_input": "2026-01-09T09:50:24.311853Z",
          "iopub.status.idle": "2026-01-09T09:50:24.324808Z",
          "shell.execute_reply.started": "2026-01-09T09:50:24.311821Z",
          "shell.execute_reply": "2026-01-09T09:50:24.324234Z"
        },
        "id": "ZCe0CTtJZ7aO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Working directory me jao\n",
        "cd /kaggle/working\n",
        "\n",
        "# sirf important files zip karo (space save)\n",
        "zip -r SHIVOM_PROJECT.zip *.csv *.pkl *.joblib *.png *.jpg 2>/dev/null || echo \"No extra files\"\n",
        "\n",
        "# ya sirf tumhari main CSV\n",
        "# zip SHIVOM_PROJECT.zip processed_output.csv\n",
        "\n",
        "echo \"Zip ready: SHIVOM_PROJECT.zip\"\n",
        "ls -la *.zip\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-09T09:51:30.391015Z",
          "iopub.execute_input": "2026-01-09T09:51:30.391301Z",
          "iopub.status.idle": "2026-01-09T09:51:30.403316Z",
          "shell.execute_reply.started": "2026-01-09T09:51:30.391276Z",
          "shell.execute_reply": "2026-01-09T09:51:30.402815Z"
        },
        "id": "Wg_WIQu6Z7aO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /kaggle/working\n",
        "ls -la *.csv *.zip 2>/dev/null || echo \"No zip found\"\n",
        "\n",
        "zip -q SHIVOM_QUICK.zip processed_output.csv 2>/dev/null\n",
        "echo \"✅ Quick zip ready: $(ls -la SHIVOM_QUICK.zip 2>/dev/null || echo 'Check files')\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-09T09:58:11.884069Z",
          "iopub.execute_input": "2026-01-09T09:58:11.884664Z",
          "iopub.status.idle": "2026-01-09T09:58:11.898772Z",
          "shell.execute_reply.started": "2026-01-09T09:58:11.884635Z",
          "shell.execute_reply": "2026-01-09T09:58:11.898233Z"
        },
        "id": "pX9-EQd7Z7aO"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}